{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analyzing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igfkOUnd5Fa0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnWHq6uAxHkw"
      },
      "source": [
        "##Importação dos dados\n",
        "Inicialmente, será importado dados para treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDP2zGEK5zPF",
        "outputId": "46e14b9f-33d3-4422-faf9-5b47c2a1ddec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Importando dados de treino\n",
        "train = pd.read_excel('/content/drive/My Drive/Colab Notebooks/handtalk/Português/emotions-pt2.xlsx')\n",
        "##train = pd.read_excel('/content/drive/My Drive/Colab Notebooks/handtalk/Português/emotions-sem-love-pt.xlsx')\n",
        "#train = pd.read_excel('datasets/emotions-pt.xlsx')\n",
        "\n",
        "#Misturando os dados\n",
        "train = train.sample(frac=1).reset_index(drop=1)\n",
        "\n",
        "#Substituindo 'alegria' por 'felicidade'\n",
        "train['sentimento'] = train['sentimento'].replace('alegria', 'felicidade')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conteúdo</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eu escolhi o inocente mundos alfabeto rosa jsk...</td>\n",
              "      <td>felicidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Eu sinto que se você ama coisinhas fofas e seu...</td>\n",
              "      <td>felicidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eu não acho que isso aconteça muito, então me ...</td>\n",
              "      <td>raiva</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Eu me sinto negligente por ter que pular todas...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eu sei que significa que ele não está se senti...</td>\n",
              "      <td>raiva</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            conteúdo  sentimento\n",
              "0  eu escolhi o inocente mundos alfabeto rosa jsk...  felicidade\n",
              "1  Eu sinto que se você ama coisinhas fofas e seu...  felicidade\n",
              "2  Eu não acho que isso aconteça muito, então me ...       raiva\n",
              "3  Eu me sinto negligente por ter que pular todas...    tristeza\n",
              "4  Eu sei que significa que ele não está se senti...       raiva"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOnl6fWtwoqi",
        "outputId": "7ce1857d-f553-4895-ff30-cb91497e6916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Importando dados para teste\n",
        "test = pd.read_excel('/content/drive/My Drive/Colab Notebooks/handtalk/Português/emotions-test-pt.xlsx')\n",
        "#test = pd.read_excel('datasets/emotions-test-pt.xlsx')\n",
        "\n",
        "#Substituindo 'alegria' por 'felicidade'\n",
        "test['sentimento'] = test['sentimento'].replace('alegria', 'felicidade')\n",
        "\n",
        "test.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conteúdo</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>estou me sentindo um tanto podre, então não so...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>estou atualizando meu blog porque me sinto uma...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eu nunca a separo de mim porque eu nunca quero...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>saí com meu buquê de tulipas vermelhas e amare...</td>\n",
              "      <td>felicidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eu estava me sentindo um pouco vaidoso quando ...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            conteúdo  sentimento\n",
              "0  estou me sentindo um tanto podre, então não so...    tristeza\n",
              "1  estou atualizando meu blog porque me sinto uma...    tristeza\n",
              "2  eu nunca a separo de mim porque eu nunca quero...    tristeza\n",
              "3  saí com meu buquê de tulipas vermelhas e amare...  felicidade\n",
              "4  Eu estava me sentindo um pouco vaidoso quando ...    tristeza"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQzpt2jN6Cdl",
        "outputId": "9533f8b7-15c8-4e20-b86d-d60dcd7639bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train['sentimento'].value_counts()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "felicidade    5362\n",
              "tristeza      4666\n",
              "raiva         2308\n",
              "Name: sentimento, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SayqdDtD7DrE",
        "outputId": "249c8fb1-1cfd-40f9-f9dc-9fb03aef77e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Retirando dados duplicados do dataset de treino\n",
        "print(f\"Antes: {train['conteúdo'].count()}\")\n",
        "\n",
        "train.drop_duplicates(inplace=True)\n",
        "print(f\"Depois: {train['conteúdo'].count()}\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes: 12336\n",
            "Depois: 12321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h4iPQaEPWvz"
      },
      "source": [
        "#Separando as sentenças dos sentimentos para o treino\n",
        "X_train = train['conteúdo']\n",
        "Y_train = train['sentimento']"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TLXxBlxxoIv"
      },
      "source": [
        "#Separando as sentenças dos sentimentos para o teste\n",
        "X_test = test['conteúdo']\n",
        "Y_test = test['sentimento']"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIeVuZxRiOha"
      },
      "source": [
        "## Preprocessamento\n",
        "Nesta etapa será definida funções para limpar os dados, além de remover as stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnm-K6a4EwH3",
        "outputId": "98850612-a89c-4daa-a12e-575061a7cc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#É necessário baixar as stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Criação da função que remove stopwords\n",
        "def remover_stopwords(conteudo):\n",
        "  stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "  stopwords.remove('não')\n",
        "\n",
        "  palavras = [p.lower() for p in conteudo.split() if p.lower() not in stopwords]\n",
        "  return \" \".join(palavras)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIduJfe2GG6k"
      },
      "source": [
        "#Criação da função de Stemming, para reduzir as palavras em radicais\n",
        "def criar_radicais(conteudo):\n",
        "  stemmer = nltk.stem.RSLPStemmer()\n",
        "  palavras = [stemmer.stem(p) for p in conteudo.split()]\n",
        "  return \" \".join(palavras)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbg4VWY8sVFL"
      },
      "source": [
        "#Criando um preprocessador para os dados\n",
        "def preprocessador(instancia):\n",
        "  #Removendo stopwords\n",
        "  stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "  stopwords.remove('não')\n",
        "\n",
        "  palavras = [p.lower() for p in conteudo.split() if p.lower() not in stopwords]\n",
        "  return \" \".join(palavras)\n",
        "\n",
        "  instancia = re.sub(\"[,.;/\\[\\]?!\\'\\\"]\", '', instancia)\n",
        "  return instancia\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT4EEoveim-0"
      },
      "source": [
        "## Classificação\n",
        "Será utilizado SVC e Naivy Bayes (MultinomialNB) para realizar o fit dos dados, além da tokenização dos dados. Por fim, será validado os modelos com o Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31mE-FS4Qjhu"
      },
      "source": [
        "#Criando um pipeline para Tokenização e Classificação\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Pipeline para Naivy Bayes\n",
        "pipe_nb = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "#Pipeline para SVC\n",
        "pipe_svc = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('svc', SVC(kernel='linear', probability=True))\n",
        "])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQo8DrMW7Ke"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "score_nb = cross_val_score(pipe_nb, X_train, Y_train, cv=6)\n",
        "score_svc = cross_val_score(pipe_svc, X_train, Y_train, cv=6)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9ajHfUFZAme",
        "outputId": "4812e185-0e46-47a8-8394-270fa762a870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f'MultinomialNB: {round(score_nb.mean(), 3)}\\nSVC: {round(score_svc.mean(), 3)}')\n",
        "#Bons resultados, por agora"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB: 0.828\n",
            "SVC: 0.856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GZgnQYx5m7"
      },
      "source": [
        "## Predições\n",
        "Será utilizado os modelos que foram treinados, e analisar qual deles terá um desempenho melhor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z5Bs2Njzv9I",
        "outputId": "6354b3d5-db00-4a27-e5e8-2032d667e0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#Fitando os dados com suas classificações\n",
        "pipe_nb.fit(X_train, Y_train)\n",
        "pipe_svc.fit(X_train, Y_train)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vetor',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1),\n",
              "                                 preprocessor=<function preprocessador at 0x7f6f3aa14e18>,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='linear', max_iter=-1,\n",
              "                     probability=True, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xoWS9dTx46N"
      },
      "source": [
        "#Realizando as predições para ambos modelos\n",
        "pred_nb = pipe_nb.predict(X_test)\n",
        "pred_svc = pipe_svc.predict(X_test)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ZDDMm60vy-",
        "outputId": "72273899-b363-4028-c672-e002ce0346ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#Medindo o desempenho do modelo para os dados de teste\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def metricas(clf, real, predito, proba=False):\n",
        "  classes = Y_train.unique().tolist()\n",
        "  \n",
        "  print(f\"\"\"{clf}\n",
        "Acurácia: {round(accuracy_score(real, predito), 3)}\n",
        "Relatório: \n",
        "{classification_report(real, predito, classes)}\"\"\")\n",
        "\n",
        "metricas('Naivy Bayes', pred_nb, Y_test)\n",
        "metricas('SVC', pred_svc, Y_test)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naivy Bayes\n",
            "Acurácia: 0.836\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  felicidade       0.92      0.86      0.89      1501\n",
            "       raiva       0.56      0.88      0.69       350\n",
            "    tristeza       0.87      0.80      0.83      1229\n",
            "\n",
            "    accuracy                           0.84      3080\n",
            "   macro avg       0.78      0.85      0.80      3080\n",
            "weighted avg       0.86      0.84      0.84      3080\n",
            "\n",
            "SVC\n",
            "Acurácia: 0.866\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  felicidade       0.93      0.88      0.90      1466\n",
            "       raiva       0.78      0.82      0.80       522\n",
            "    tristeza       0.83      0.86      0.85      1092\n",
            "\n",
            "    accuracy                           0.87      3080\n",
            "   macro avg       0.85      0.86      0.85      3080\n",
            "weighted avg       0.87      0.87      0.87      3080\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQQES9U0wsQ",
        "outputId": "7ed52483-458e-48c2-b918-a0d2ab03c426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#Agora um teste com frases próprias\n",
        "frases = ['Passei na prova da faculdade', #felicidade\n",
        "         'Estou cansado, passei o dia todo trabalhando', #tristeza\n",
        "         'Vou bater no próximo que aparecer na minha frente', #raiva\n",
        "         'Tenho as melhores pessoas ao meu lado', #felicidade\n",
        "         'Confesso que tenho vontade de espancar certa pessoa', #raiva\n",
        "         'Estou muito feliz'] #felicidade\n",
        "\n",
        "#Probabilidade das classes\n",
        "proba_nb = pipe_nb.predict_proba(frases)\n",
        "proba_svc = pipe_svc.predict_proba(frases)\n",
        "\n",
        "classes = ['felicidade', 'raiva', 'tristeza']\n",
        "print(f'NB:\\nClassificações: {[classes[i] for i in np.argmax(proba_nb, axis=1)]}\\nProbabilidades: {proba_nb}')\n",
        "print(f'\\n\\nSVC:\\nClassificações: {[classes[i] for i in np.argmax(proba_svc, axis=1)]}\\nProbabilidades: {proba_svc}')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB:\n",
            "Classificações: ['felicidade', 'tristeza', 'felicidade', 'felicidade', 'raiva', 'felicidade']\n",
            "Probabilidades: [[0.58955438 0.07701973 0.3334259 ]\n",
            " [0.13648878 0.02379798 0.83971324]\n",
            " [0.58431933 0.17006785 0.24561282]\n",
            " [0.47792894 0.18461559 0.33745547]\n",
            " [0.44798615 0.5141294  0.03788446]\n",
            " [0.78156837 0.05636907 0.16206256]]\n",
            "\n",
            "\n",
            "SVC:\n",
            "Classificações: ['felicidade', 'tristeza', 'raiva', 'felicidade', 'raiva', 'felicidade']\n",
            "Probabilidades: [[0.45948061 0.19182376 0.34869562]\n",
            " [0.04152714 0.0545191  0.90395376]\n",
            " [0.16166227 0.68532826 0.15300946]\n",
            " [0.37131267 0.31647414 0.31221319]\n",
            " [0.2289892  0.71077128 0.06023952]\n",
            " [0.88129333 0.05622704 0.06247963]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmXeyXlz0xki"
      },
      "source": [
        "## Fine Tuning\n",
        "Apesar dos resultados serem satisfatórios, é possível melhora. Para isto, seraárealizado ajuste de hiperparâmetros, com a procura da melhor combinação destes, utilizando o GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-4ebVTYbhrS"
      },
      "source": [
        "#Introdução do TfidfTransformer, para aumentar os pesos das palavras mais importantes\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#Pipeline para Naivy Bayes\n",
        "pipe_nb2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "#Pipeline para SVC\n",
        "pipe_svc2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('svc', SVC(kernel='linear', probability=True))\n",
        "])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HbCKfReISXl",
        "outputId": "e5321d47-80ef-451c-b075-494596a88231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "#Função para automatizar etapas finais\n",
        "def resultados_fine_tuning(X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test, frases=frases):\n",
        "  pipe_nb2.fit(X_train, Y_train)\n",
        "  pipe_svc2.fit(X_train, Y_train)\n",
        "\n",
        "  pred_nb = pipe_nb2.predict(X_test)\n",
        "  pred_svc = pipe_svc2.predict(X_test)\n",
        "\n",
        "  metricas('Naivy Bayes', pred_nb, Y_test)\n",
        "  metricas('SVC', pred_svc, Y_test)\n",
        "\n",
        "  frases_nb = pipe_nb.predict(frases)\n",
        "  frases_svc = pipe_svc.predict(frases)\n",
        "\n",
        "  print(f'\\n\\nPredições Customizadas:\\nNB: {frases_nb}\\nSVC: {frases_svc}')\n",
        "\n",
        "resultados_fine_tuning()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naivy Bayes\n",
            "Acurácia: 0.783\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    tristeza       0.84      0.78      0.81      1223\n",
            "       raiva       0.23      0.98      0.38       130\n",
            "     alegria       0.95      0.77      0.85      1727\n",
            "\n",
            "    accuracy                           0.78      3080\n",
            "   macro avg       0.68      0.84      0.68      3080\n",
            "weighted avg       0.88      0.78      0.81      3080\n",
            "\n",
            "SVC\n",
            "Acurácia: 0.873\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    tristeza       0.85      0.87      0.86      1110\n",
            "       raiva       0.72      0.89      0.80       446\n",
            "     alegria       0.95      0.87      0.91      1524\n",
            "\n",
            "    accuracy                           0.87      3080\n",
            "   macro avg       0.84      0.88      0.86      3080\n",
            "weighted avg       0.88      0.87      0.88      3080\n",
            "\n",
            "\n",
            "\n",
            "Predições Customizadas:\n",
            "NB: [[0.5272885  0.10762202 0.36508948]\n",
            " [0.31179607 0.06068371 0.62752022]\n",
            " [0.51636067 0.14674049 0.33689884]\n",
            " [0.50212991 0.13716251 0.36070757]\n",
            " [0.5207083  0.29031608 0.18897562]\n",
            " [0.81925459 0.04177565 0.13896977]]\n",
            "SVC: [[5.05392800e-01 6.69300932e-02 4.27677106e-01]\n",
            " [2.11198987e-02 1.06116531e-02 9.68268448e-01]\n",
            " [3.33381775e-01 4.59800121e-01 2.06818105e-01]\n",
            " [3.54308907e-01 2.62182284e-01 3.83508809e-01]\n",
            " [5.00171042e-02 9.45863867e-01 4.11902837e-03]\n",
            " [9.99993656e-01 2.51172888e-06 3.83211713e-06]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpSHuNzOQMPs"
      },
      "source": [
        "Resultado parecido com o original, com queda de rendimento para classificar 'raiva', além de aumentar o tempo do fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nf1LxPEIiG7"
      },
      "source": [
        "#Parâmetros para serem analisados\n",
        "params = {\n",
        "    'vetor__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__use_norm': (None, 'l1', 'l2')\n",
        "}\n",
        "\n",
        "#Parâmetros exclusivo do Naivy Bayes\n",
        "params_nb = {'nb__alpha': (1e-2, 1e-3), 'nb__fit_prior': [True, False]}\n",
        "params_nb.update(params)\n",
        "\n",
        "#Parâmetros exclusivo do SVC\n",
        "params_svc = {\n",
        "    'svc__kernel': ['linear', 'rbf', 'poly'],\n",
        "    'svc__gamma': [0.1, 1, 10, 100],\n",
        "    'svc__c': [0.1, 1, 10, 100]\n",
        "}\n",
        "params_svc.update(params)\n",
        "\n",
        "#Pipeline para Naivy Bayes\n",
        "pipe_nb2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "#Pipeline para SVC\n",
        "pipe_svc2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('svc', SVC(kernel='linear', probability=True))\n",
        "])"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w88ztBfWu0L"
      },
      "source": [
        "#Utilizando o GridSearchCV para realizar o ajuste dos parâmetros\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#GridSearch para Naivy Bayes\n",
        "nb_gs = GridSearchCV(pipe_nb2, params_nb, cv=3)\n",
        "print(f'Score: {nb_gs.best_score_}')\n",
        "print(f'Parâmetros: {nb_gs.best_params_}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op5oX9nuXApU"
      },
      "source": [
        "#GridSearch para SVC\n",
        "svc_gs = GridSearchCV(pipe_svc2, params_svc, cv=3)\n",
        "print(f'Score: {svc_gs.best_score_}')\n",
        "print(f'Parâmetros: {svc_gs.best_params_}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBgKqAoZXqI8"
      },
      "source": [
        "## Salvando o modelo\n",
        "Para que a utilização do modelo escolhido seja mais fácil e prática, o modelo será salvo, utilizando o joblib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3O6wazYYAp2",
        "outputId": "059ceb5b-414b-451d-9504-497640c23306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "#Salvando o modelo com melhor performance // MUDAR ESTA PARTE DO CÓDIGO\n",
        "joblib.dump(pipe_svc, '/content/drive/My Drive/Colab Notebooks/handtalk/model.sav')\n",
        "#joblib.dump(pipe_svc, 'model/model.sav')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Colab Notebooks/handtalk/model.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO8qeXduZCGA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}