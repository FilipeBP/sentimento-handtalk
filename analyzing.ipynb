{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analyzing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "igfkOUnd5Fa0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnWHq6uAxHkw"
      },
      "source": [
        "##Importação dos dados\n",
        "Inicialmente, será importado dados para treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDP2zGEK5zPF",
        "outputId": "a7988155-bad2-4816-8f99-0cb3fcce8395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Importando dados de treino\n",
        "train = pd.read_excel('/content/drive/My Drive/Colab Notebooks/handtalk/Português/emotions-pt2.xlsx')\n",
        "##train = pd.read_excel('/content/drive/My Drive/Colab Notebooks/handtalk/Português/emotions-sem-love-pt.xlsx')\n",
        "#train = pd.read_excel('datasets/emotions-pt2.xlsx')\n",
        "\n",
        "#Misturando os dados\n",
        "train = train.sample(frac=1).reset_index(drop=1)\n",
        "\n",
        "#Substituindo 'alegria' por 'felicidade'\n",
        "train['sentimento'] = train['sentimento'].replace('alegria', 'felicidade')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conteúdo</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eu acho que o homem sabe como fazer cada um de...</td>\n",
              "      <td>felicidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>me sinto espancado e machucado por sua asperez...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eu me sinto honrado em ser testemunha do proce...</td>\n",
              "      <td>felicidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Já estou me sentindo sentimental sobre seu tem...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eu abro meus olhos de manhã meu coração parece...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            conteúdo  sentimento\n",
              "0  eu acho que o homem sabe como fazer cada um de...  felicidade\n",
              "1  me sinto espancado e machucado por sua asperez...    tristeza\n",
              "2  Eu me sinto honrado em ser testemunha do proce...  felicidade\n",
              "3  Já estou me sentindo sentimental sobre seu tem...    tristeza\n",
              "4  eu abro meus olhos de manhã meu coração parece...    tristeza"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOnl6fWtwoqi",
        "outputId": "90db5a64-6bbe-4d4e-edba-730af240f10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Importando dados para teste\n",
        "test = pd.read_excel('/content/drive/My Drive/Colab Notebooks/handtalk/Português/emotions-test-pt.xlsx')\n",
        "#test = pd.read_excel('datasets/emotions-test-pt.xlsx')\n",
        "\n",
        "#Substituindo 'alegria' por 'felicidade'\n",
        "test['sentimento'] = test['sentimento'].replace('alegria', 'felicidade')\n",
        "\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conteúdo</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>estou me sentindo um tanto podre, então não so...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>estou atualizando meu blog porque me sinto uma...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eu nunca a separo de mim porque eu nunca quero...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>saí com meu buquê de tulipas vermelhas e amare...</td>\n",
              "      <td>felicidade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Eu estava me sentindo um pouco vaidoso quando ...</td>\n",
              "      <td>tristeza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            conteúdo  sentimento\n",
              "0  estou me sentindo um tanto podre, então não so...    tristeza\n",
              "1  estou atualizando meu blog porque me sinto uma...    tristeza\n",
              "2  eu nunca a separo de mim porque eu nunca quero...    tristeza\n",
              "3  saí com meu buquê de tulipas vermelhas e amare...  felicidade\n",
              "4  Eu estava me sentindo um pouco vaidoso quando ...    tristeza"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQzpt2jN6Cdl",
        "outputId": "9533f8b7-15c8-4e20-b86d-d60dcd7639bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train['sentimento'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "felicidade    5362\n",
              "tristeza      4666\n",
              "raiva         2308\n",
              "Name: sentimento, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SayqdDtD7DrE",
        "outputId": "9845dcd4-b874-46ac-8fbb-d47887bc117e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Retirando dados duplicados do dataset de treino\n",
        "print(f\"Antes: {train['conteúdo'].count()}\")\n",
        "\n",
        "train.drop_duplicates(inplace=True)\n",
        "print(f\"Depois: {train['conteúdo'].count()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Antes: 12336\n",
            "Depois: 12321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h4iPQaEPWvz"
      },
      "source": [
        "#Separando as sentenças dos sentimentos para o treino\n",
        "X_train = train['conteúdo']\n",
        "Y_train = train['sentimento']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TLXxBlxxoIv"
      },
      "source": [
        "#Separando as sentenças dos sentimentos para o teste\n",
        "X_test = test['conteúdo']\n",
        "Y_test = test['sentimento']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIeVuZxRiOha"
      },
      "source": [
        "## Preprocessamento\n",
        "Nesta etapa será definida funções para limpar os dados, além de remover as stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIduJfe2GG6k"
      },
      "source": [
        "#Criação da função de Stemming, para reduzir as palavras em radicais\n",
        "def criar_radicais(conteudo):\n",
        "  stemmer = nltk.stem.RSLPStemmer()\n",
        "  palavras = [stemmer.stem(p) for p in conteudo.split()]\n",
        "  return \" \".join(palavras)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbg4VWY8sVFL",
        "outputId": "0bb78c38-048b-49b3-c929-60a4b8b5ffe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Efetiva-se um transformador customizado para o pré-processamento\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    #Baixa as stopwords\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "\n",
        "  def transform(self, X, y=None):\n",
        "    if isinstance(X, pd.core.series.Series) or isinstance(X, pd.core.frame.DataFrame):\n",
        "      return X.apply(lambda x: self.preprocessador(x))\n",
        "    if isinstance(X, list):\n",
        "      return map(lambda x: self.preprocessador(x), X)\n",
        "\n",
        "  def preprocessador(self, instancia):\n",
        "    #Removendo stopwords\n",
        "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "    stopwords.remove('não')\n",
        "\n",
        "    #Removendo caracteres indesejados\n",
        "    instancia = [p.lower() for p in instancia.split() if p.lower() not in stopwords]\n",
        "    instancia = \" \".join(instancia)\n",
        "\n",
        "    instancia = re.sub(\"[,.;/\\[\\]?!\\'\\\"]\", '', instancia)\n",
        "    return instancia\n",
        "\n",
        "  pre = CustomTransformer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT4EEoveim-0"
      },
      "source": [
        "## Classificação\n",
        "Será utilizado SVC e Naivy Bayes (MultinomialNB) para realizar o fit dos dados, além da tokenização dos dados. Por fim, será validado os modelos com o Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31mE-FS4Qjhu"
      },
      "source": [
        "#Criando um pipeline para Tokenização e Classificação\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Pipeline para Naivy Bayes\n",
        "pipe_nb = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word')),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "#Pipeline para SVC\n",
        "pipe_svc = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word')),\n",
        "    ('svc', SVC(kernel='linear', probability=True))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCKoiVicjaL3"
      },
      "source": [
        "#Pré-processando os dados\n",
        "X_train = pre.transform(X_train)\n",
        "X_test = pre.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQo8DrMW7Ke"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "score_nb = cross_val_score(pipe_nb, X_train, Y_train, cv=6)\n",
        "score_svc = cross_val_score(pipe_svc, X_train, Y_train, cv=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9ajHfUFZAme",
        "outputId": "4812e185-0e46-47a8-8394-270fa762a870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f'MultinomialNB: {round(score_nb.mean(), 3)}\\nSVC: {round(score_svc.mean(), 3)}')\n",
        "#Bons resultados, por agora"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB: 0.828\n",
            "SVC: 0.856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8GZgnQYx5m7"
      },
      "source": [
        "## Predições\n",
        "Será utilizado os modelos que foram treinados, e analisar qual deles terá um desempenho melhor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z5Bs2Njzv9I",
        "outputId": "6354b3d5-db00-4a27-e5e8-2032d667e0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#Fitando os dados com suas classificações\n",
        "pipe_nb.fit(X_train, Y_train)\n",
        "pipe_svc.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vetor',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1),\n",
              "                                 preprocessor=<function preprocessador at 0x7f6f3aa14e18>,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='linear', max_iter=-1,\n",
              "                     probability=True, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xoWS9dTx46N"
      },
      "source": [
        "#Realizando as predições para ambos modelos\n",
        "pred_nb = pipe_nb.predict(X_test)\n",
        "pred_svc = pipe_svc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ZDDMm60vy-",
        "outputId": "72273899-b363-4028-c672-e002ce0346ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#Medindo o desempenho do modelo para os dados de teste\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def metricas(clf, real, predito, proba=False):\n",
        "  classes = Y_train.unique().tolist()\n",
        "  \n",
        "  print(f\"\"\"{clf}\n",
        "Acurácia: {round(accuracy_score(real, predito), 3)}\n",
        "Relatório: \n",
        "{classification_report(real, predito, classes)}\"\"\")\n",
        "\n",
        "metricas('Naivy Bayes', pred_nb, Y_test)\n",
        "metricas('SVC', pred_svc, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naivy Bayes\n",
            "Acurácia: 0.836\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  felicidade       0.92      0.86      0.89      1501\n",
            "       raiva       0.56      0.88      0.69       350\n",
            "    tristeza       0.87      0.80      0.83      1229\n",
            "\n",
            "    accuracy                           0.84      3080\n",
            "   macro avg       0.78      0.85      0.80      3080\n",
            "weighted avg       0.86      0.84      0.84      3080\n",
            "\n",
            "SVC\n",
            "Acurácia: 0.866\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  felicidade       0.93      0.88      0.90      1466\n",
            "       raiva       0.78      0.82      0.80       522\n",
            "    tristeza       0.83      0.86      0.85      1092\n",
            "\n",
            "    accuracy                           0.87      3080\n",
            "   macro avg       0.85      0.86      0.85      3080\n",
            "weighted avg       0.87      0.87      0.87      3080\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQQES9U0wsQ",
        "outputId": "7ed52483-458e-48c2-b918-a0d2ab03c426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#Agora um teste com frases próprias\n",
        "frases = ['Passei na prova da faculdade', #felicidade\n",
        "         'Estou cansado, passei o dia todo trabalhando', #tristeza\n",
        "         'Vou bater no próximo que aparecer na minha frente', #raiva\n",
        "         'Tenho as melhores pessoas ao meu lado', #felicidade\n",
        "         'Confesso que tenho vontade de espancar certa pessoa', #raiva\n",
        "         'Estou muito feliz'] #felicidade\n",
        "\n",
        "#Pré-processamento\n",
        "frases = pre.transform(frases)\n",
        "\n",
        "#Probabilidade das classes\n",
        "proba_nb = pipe_nb.predict_proba(frases)\n",
        "proba_svc = pipe_svc.predict_proba(frases)\n",
        "\n",
        "classes = ['felicidade', 'raiva', 'tristeza']\n",
        "print(f'NB:\\nClassificações: {[classes[i] for i in np.argmax(proba_nb, axis=1)]}\\nProbabilidades: {proba_nb}')\n",
        "print(f'\\n\\nSVC:\\nClassificações: {[classes[i] for i in np.argmax(proba_svc, axis=1)]}\\nProbabilidades: {proba_svc}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB:\n",
            "Classificações: ['felicidade', 'tristeza', 'felicidade', 'felicidade', 'raiva', 'felicidade']\n",
            "Probabilidades: [[0.58955438 0.07701973 0.3334259 ]\n",
            " [0.13648878 0.02379798 0.83971324]\n",
            " [0.58431933 0.17006785 0.24561282]\n",
            " [0.47792894 0.18461559 0.33745547]\n",
            " [0.44798615 0.5141294  0.03788446]\n",
            " [0.78156837 0.05636907 0.16206256]]\n",
            "\n",
            "\n",
            "SVC:\n",
            "Classificações: ['felicidade', 'tristeza', 'raiva', 'felicidade', 'raiva', 'felicidade']\n",
            "Probabilidades: [[0.45948061 0.19182376 0.34869562]\n",
            " [0.04152714 0.0545191  0.90395376]\n",
            " [0.16166227 0.68532826 0.15300946]\n",
            " [0.37131267 0.31647414 0.31221319]\n",
            " [0.2289892  0.71077128 0.06023952]\n",
            " [0.88129333 0.05622704 0.06247963]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmXeyXlz0xki"
      },
      "source": [
        "## Fine Tuning\n",
        "Apesar dos resultados serem satisfatórios, é possível melhora. Para isto, seraárealizado ajuste de hiperparâmetros, com a procura da melhor combinação destes, utilizando o GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-4ebVTYbhrS"
      },
      "source": [
        "#Introdução do TfidfTransformer, para aumentar os pesos das palavras mais importantes\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "#Pipeline para Naivy Bayes\n",
        "pipe_nb2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "#Pipeline para SVC\n",
        "pipe_svc2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('svc', SVC(kernel='linear', probability=True))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HbCKfReISXl",
        "outputId": "e5321d47-80ef-451c-b075-494596a88231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "#Função para automatizar etapas finais\n",
        "def resultados_fine_tuning(X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test, frases=frases):\n",
        "  pipe_nb2.fit(X_train, Y_train)\n",
        "  pipe_svc2.fit(X_train, Y_train)\n",
        "\n",
        "  pred_nb = pipe_nb2.predict(X_test)\n",
        "  pred_svc = pipe_svc2.predict(X_test)\n",
        "\n",
        "  metricas('Naivy Bayes', pred_nb, Y_test)\n",
        "  metricas('SVC', pred_svc, Y_test)\n",
        "\n",
        "  frases_nb = pipe_nb.predict(frases)\n",
        "  frases_svc = pipe_svc.predict(frases)\n",
        "\n",
        "  print(f'\\n\\nPredições Customizadas:\\nNB: {frases_nb}\\nSVC: {frases_svc}')\n",
        "\n",
        "resultados_fine_tuning()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naivy Bayes\n",
            "Acurácia: 0.783\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    tristeza       0.84      0.78      0.81      1223\n",
            "       raiva       0.23      0.98      0.38       130\n",
            "     alegria       0.95      0.77      0.85      1727\n",
            "\n",
            "    accuracy                           0.78      3080\n",
            "   macro avg       0.68      0.84      0.68      3080\n",
            "weighted avg       0.88      0.78      0.81      3080\n",
            "\n",
            "SVC\n",
            "Acurácia: 0.873\n",
            "Relatório: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    tristeza       0.85      0.87      0.86      1110\n",
            "       raiva       0.72      0.89      0.80       446\n",
            "     alegria       0.95      0.87      0.91      1524\n",
            "\n",
            "    accuracy                           0.87      3080\n",
            "   macro avg       0.84      0.88      0.86      3080\n",
            "weighted avg       0.88      0.87      0.88      3080\n",
            "\n",
            "\n",
            "\n",
            "Predições Customizadas:\n",
            "NB: [[0.5272885  0.10762202 0.36508948]\n",
            " [0.31179607 0.06068371 0.62752022]\n",
            " [0.51636067 0.14674049 0.33689884]\n",
            " [0.50212991 0.13716251 0.36070757]\n",
            " [0.5207083  0.29031608 0.18897562]\n",
            " [0.81925459 0.04177565 0.13896977]]\n",
            "SVC: [[5.05392800e-01 6.69300932e-02 4.27677106e-01]\n",
            " [2.11198987e-02 1.06116531e-02 9.68268448e-01]\n",
            " [3.33381775e-01 4.59800121e-01 2.06818105e-01]\n",
            " [3.54308907e-01 2.62182284e-01 3.83508809e-01]\n",
            " [5.00171042e-02 9.45863867e-01 4.11902837e-03]\n",
            " [9.99993656e-01 2.51172888e-06 3.83211713e-06]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpSHuNzOQMPs"
      },
      "source": [
        "Resultado parecido com o original, com queda de rendimento para classificar 'raiva', além de aumentar o tempo do fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nf1LxPEIiG7"
      },
      "source": [
        "#Utilizando o GridSearchCV para realizar o ajuste dos parâmetros\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Parâmetros para serem analisados\n",
        "params = {\n",
        "    'vetor__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': (None, 'l1', 'l2')\n",
        "}\n",
        "\n",
        "#Parâmetros exclusivo do Naivy Bayes\n",
        "params_nb = {'nb__alpha': (1e-2, 1e-3), 'nb__fit_prior': [True, False]}\n",
        "params_nb.update(params)\n",
        "\n",
        "#Parâmetros exclusivo do SVC\n",
        "params_svc = {\n",
        "    'svc__kernel': ['linear', 'rbf'],\n",
        "    'svc__gamma': [0.1, 1, 10],\n",
        "    'svc__C': [0.1, 1, 10]\n",
        "}\n",
        "params_svc.update(params)\n",
        "\n",
        "#Pipeline para Naivy Bayes\n",
        "pipe_nb2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('nb', MultinomialNB())\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w88ztBfWu0L"
      },
      "source": [
        "#GridSearch para Naivy Bayes\n",
        "nb_gs = GridSearchCV(pipe_nb2, params_nb, cv=3, verbose=2)\n",
        "nb_gs = nb_gs.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJTJLKBjk_KY",
        "outputId": "f8dfeda3-0b40-49c8-9312-324729b93acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(f'Score: {nb_gs.best_score_}')\n",
        "print(f'Parâmetros: {nb_gs.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.833860887914942\n",
            "Parâmetros: {'nb__alpha': 0.01, 'nb__fit_prior': False, 'tfidf__norm': 'l1', 'tfidf__use_idf': False, 'vetor__ngram_range': (1, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQqMHYq5Dgbp"
      },
      "source": [
        "Para uma SVC, o treinamento estava demorando bastante. Para tentar reduzir o tempo de treinamento, será utilizado o BaggingClassifier, em que terá 10 SVCs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYZSAPNTD4aj"
      },
      "source": [
        "#Utilização do Bagging Classifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "#Quantidade de estimadores\n",
        "n_est = 10\n",
        "\n",
        "#Parâmetros exclusivo do SVC\n",
        "params_svc = {\n",
        "    'clf__base_estimator__kernel': ['linear', 'rbf'],\n",
        "    'clf__base_estimator__gamma': [0.1, 1, 10],\n",
        "    'clf__base_estimator__C': [0.1, 1, 10]\n",
        "}\n",
        "params_svc.update(params)\n",
        "\n",
        "clf = BaggingClassifier(SVC(probability=True), max_samples=1.0/n_est, n_estimators=n_est)\n",
        "\n",
        "#Pipeline para SVC\n",
        "pipe_svc2 = Pipeline([\n",
        "    ('vetor', CountVectorizer(analyzer='word', preprocessor=preprocessador)),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', clf)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op5oX9nuXApU",
        "outputId": "81826997-8d8a-4330-f1bb-a98ff7b669c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#GridSearch para SVC\n",
        "svc_gs = GridSearchCV(pipe_svc2, params_svc, cv=3, verbose=2, n_jobs=-1)\n",
        "svc_gs = svc_gs.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed: 52.2min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed: 94.2min\n",
            "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed: 143.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q75skRR4iqAJ",
        "outputId": "d0bd6859-8ad2-4f86-de4c-e238057371c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(f'Score: {svc_gs.best_score_}')\n",
        "print(f'Parâmetros: {svc_gs.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.7940102264426588\n",
            "Parâmetros: {'clf__base_estimator__C': 0.1, 'clf__base_estimator__gamma': 1, 'clf__base_estimator__kernel': 'linear', 'tfidf__norm': None, 'tfidf__use_idf': True, 'vetor__ngram_range': (1, 1)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czAXC5D5nhUH"
      },
      "source": [
        "Surpreendentemente, o classificador de SVC apresentou resultados piores após o ajuste de parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBgKqAoZXqI8"
      },
      "source": [
        "## Salvando o modelo\n",
        "Para que a utilização do modelo escolhido seja mais fácil e prática, o modelo será salvo, utilizando o joblib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3O6wazYYAp2"
      },
      "source": [
        "import joblib\n",
        "\n",
        "#Salvando o modelo com melhor performance\n",
        "joblib.dump(pipe_svc, '/content/drive/My Drive/Colab Notebooks/handtalk/model.sav')\n",
        "#joblib.dump(pipe_svc, 'model/model.sav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO8qeXduZCGA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}